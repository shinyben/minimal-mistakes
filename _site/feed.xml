<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-08-11T16:11:00-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Ben Gardner</title><subtitle>CS student at MIT</subtitle><author><name>Ben Gardner</name></author><entry><title type="html">Reaction to Peter Theil’s Article</title><link href="http://localhost:4000/Reaction-to-Theil/" rel="alternate" type="text/html" title="Reaction to Peter Theil's Article" /><published>2019-08-10T00:00:00-04:00</published><updated>2019-08-10T00:00:00-04:00</updated><id>http://localhost:4000/Reaction-to-Theil</id><content type="html" xml:base="http://localhost:4000/Reaction-to-Theil/">&lt;p&gt;Peter Theil, an entrepreneur behind PayPal, Palantir, and Founder’s Fund recently wrote an op-ed for the New York Times entitled &lt;a href=&quot;https://www.nytimes.com/2019/08/01/opinion/peter-thiel-google.html&quot;&gt;“Good for Google, Bad for America”&lt;/a&gt; that dealt with AI. His position can be summarized by “AI is inherently a military technology, but Google seems to be sharing its work with a malevolent foreign power. We should be worried about that, and not let Google escape criticism.” This is in response to Google’s Fei-Fei Li’s opening of a basic AI research lab in China.&lt;/p&gt;

&lt;p&gt;First, let’s look at “AI is inherently a military technology.” I’m currently using this ‘militaristic’ technology to classify video game trading cards, but let’s ignore that part. I think I’m going to rely on a lesson taught to me by the Superfriends in the episode &lt;a href=&quot;https://www.imdb.com/title/tt0776309/&quot;&gt;Monolith of Evil&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/2019-8-10-Reaction-to-Theil/superfriends.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For backstory, the Legion of Doom finds something they call the “Monolith of Evil”, an all-powerful tool that can do pretty much anything. They wreak havoc with it, creating an ice monster that attempts to destroy a bridge, among other things. The Superfriends win by using the Monolith against the Legion of Doom, prompting Grodd (of the Legion) to say “I don’t understand. How could the Superfriends control the forces of evil?” Batman responds with “It wasn’t an evil power source, Grodd. But, like anything else, becomes good or bad depending on how it’s put to use.”&lt;/p&gt;

&lt;p&gt;AI, I think, is the same way. Sure, there are militaristic applications such as Project Maven, but overall AI’s uses in healthcare, autonomous driving, finance, and other sectors show that the applications that harm humans are the exception, not the rule.&lt;/p&gt;

&lt;p&gt;As an aside, though, it seems to me that advances in computing historically stem from the military: magnetic-core memory&lt;sup&gt;[&lt;a href=&quot;https://en.wikipedia.org/wiki/Whirlwind_I&quot;&gt;1&lt;/a&gt;]&lt;/sup&gt;, electronic general-purpose computing&lt;sup&gt;[&lt;a href=&quot;https://en.wikipedia.org/wiki/ENIAC&quot;&gt;2&lt;/a&gt;]&lt;/sup&gt;, and bombes&lt;sup&gt;[&lt;a href=&quot;https://en.wikipedia.org/wiki/Bombe&quot;&gt;3&lt;/a&gt;]&lt;/sup&gt; all were US military projects.&lt;/p&gt;

&lt;p&gt;Incidentally, while they remain relevant, these initiatives remain largely secret, such as the Enigma decoders not being acknowledged publicly until 1970&lt;sup&gt;[&lt;a href=&quot;https://en.wikipedia.org/wiki/Enigma_machine#Surviving_machines&quot;&gt;4&lt;/a&gt;]&lt;/sup&gt; despite being designed in 1939.&lt;/p&gt;

&lt;p&gt;Next, let’s look at China. Theil raises several points, so let’s delve into them.&lt;/p&gt;

&lt;p&gt;First, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Great_Firewall&quot;&gt;Great Firewall&lt;/a&gt;. Google’s justification for going abroad with their research efforts was that ‘AI and its benefits have no borders.’&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/2019-8-10-Reaction-to-Theil/firewall.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I think this point is valid. In a bit of a parallel to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Paradox_of_tolerance&quot;&gt;Paradox of Tolerance&lt;/a&gt;, being open with technology that could be used for suppression would lead to suppression in this case, not openness. I agree with Theil that Google is being a bit naive in this case.&lt;/p&gt;

&lt;p&gt;Next, civil-military fusion. “This” refers to Ash Carter’s pointing out that “If you’re working in China, you don’t know whether you’re working on a project for the military or not.&lt;sup&gt;[&lt;a href=&quot;https://www.cnbc.com/2019/07/18/ex-defense-secretary-ash-carter-google-has-a-duty-to-the-us-not-china.html&quot;&gt;5&lt;/a&gt;]&lt;/sup&gt;”&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/2019-8-10-Reaction-to-Theil/civil-military-fusion.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Looking around on Twitter, though, it seems the author has something to say about the use of his linked article:&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;It&amp;#39;s really nice that Thiel linked my article on military-civil fusion in this NYT op-ed. &lt;br /&gt;&lt;br /&gt;Too bad he didn&amp;#39;t read it. Bc, if he did, he wouldn&amp;#39;t make an erroneous claim like MCF &amp;quot;mandates that all research done in China be shared with the [PLA]&amp;quot; &lt;a href=&quot;https://t.co/hM7PxEMKGK&quot;&gt;https://t.co/hM7PxEMKGK&lt;/a&gt;&lt;/p&gt;&amp;mdash; Lorand Laskai (@lorandlaskai) &lt;a href=&quot;https://twitter.com/lorandlaskai/status/1157314963821735936?ref_src=twsrc%5Etfw&quot;&gt;August 2, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;This op-ed also bigger than just a discussion about the applications of AI. Theil’s op-ed seems to have reached the Trumps as well, with both Trump and Trump Jr. tweeting about it:&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Peter Thiel Slams Google for Sharing AI Technology with China | Breitbart &lt;a href=&quot;https://t.co/D9LLL5cXXs&quot;&gt;https://t.co/D9LLL5cXXs&lt;/a&gt; via &lt;a href=&quot;https://twitter.com/BreitbartNews?ref_src=twsrc%5Etfw&quot;&gt;@BreitbartNews&lt;/a&gt;&lt;/p&gt;&amp;mdash; Donald Trump Jr. (@DonaldJTrumpJr) &lt;a href=&quot;https://twitter.com/DonaldJTrumpJr/status/1157420939392540672?ref_src=twsrc%5Etfw&quot;&gt;August 2, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;“Billionaire Tech Investor Peter Thiel believes Google should be investigated for treason. He accuses Google of working with the Chinese Government.” &lt;a href=&quot;https://twitter.com/foxandfriends?ref_src=twsrc%5Etfw&quot;&gt;@foxandfriends&lt;/a&gt;  A great and brilliant guy who knows this subject better than anyone! The Trump Administration will take a look!&lt;/p&gt;&amp;mdash; Donald J. Trump (@realDonaldTrump) &lt;a href=&quot;https://twitter.com/realDonaldTrump/status/1151095675213553664?ref_src=twsrc%5Etfw&quot;&gt;July 16, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;</content><author><name>Ben Gardner</name></author><summary type="html">Peter Theil, an entrepreneur behind PayPal, Palantir, and Founder’s Fund recently wrote an op-ed for the New York Times entitled “Good for Google, Bad for America” that dealt with AI. His position can be summarized by “AI is inherently a military technology, but Google seems to be sharing its work with a malevolent foreign power. We should be worried about that, and not let Google escape criticism.” This is in response to Google’s Fei-Fei Li’s opening of a basic AI research lab in China.</summary></entry><entry><title type="html">Reaction to Rich Sutton’s Blogpost</title><link href="http://localhost:4000/Reaction-to-Sutton/" rel="alternate" type="text/html" title="Reaction to Rich Sutton's Blogpost" /><published>2019-04-20T00:00:00-04:00</published><updated>2019-04-20T00:00:00-04:00</updated><id>http://localhost:4000/Reaction-to-Sutton</id><content type="html" xml:base="http://localhost:4000/Reaction-to-Sutton/">&lt;p&gt;Rich Sutton, a professor of Reinforcement Learning (RL) at the University of Alberta and the guy who wrote the book on RL, recently wrote a blogpost entitled &lt;a href=&quot;http://www.incompleteideas.net/IncIdeas/BitterLesson.html&quot;&gt;“The Bitter Lesson”&lt;/a&gt;. To summarize, “General methods augmented by massive computation are the most effective. Attempts to ‘put’ human knowledge into systems make the systems plateau and ultimately fail.”&lt;/p&gt;

&lt;p&gt;First, the post summarizes progress made in the games Go and chess, and then speech recognition, deep learning, and computer vision. Sutton points out that, in all cases, statistical methods that utilize massive computation have won out over the efforts that attempt to make the computer ‘think the way humans think’ and plug in human heuristics.&lt;/p&gt;

&lt;p&gt;It’s a rather short blogpost, and I would recommend reading it yourself, but I’ve pulled out several quotes that I think summarize its feel rather nicely:&lt;/p&gt;

&lt;blockquote&gt;The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective, and by a large margin.&lt;/blockquote&gt;

&lt;blockquote&gt;Search and learning are the two most important classes of techniques for utilizing massive amounts of computation in AI research.&lt;/blockquote&gt;

&lt;blockquote&gt;Again, the statistical methods won out over the human-knowledge-based methods. This led to a major change in all of natural language processing, gradually over decades, where statistics and computation came to dominate the field.&lt;/blockquote&gt;

&lt;blockquote&gt;As in the games (chess and Go), researchers always tried to make systems that worked the way the researchers thought their own minds worked---they tried to put that knowledge in their systems---but it proved ultimately counterproductive, and a colossal waste of researcher's time, when, through Moore's law, massive computation became available and a means was found to put it to good use.&lt;/blockquote&gt;

&lt;blockquote&gt;The second general point to be learned from the bitter lesson is that the actual contents of minds are tremendously, irredeemably complex; we should stop trying to find simple ways to think about the contents of minds, such as simple ways to think about space, objects, multiple agents, or symmetries.&lt;/blockquote&gt;</content><author><name>Ben Gardner</name></author><summary type="html">Rich Sutton, a professor of Reinforcement Learning (RL) at the University of Alberta and the guy who wrote the book on RL, recently wrote a blogpost entitled “The Bitter Lesson”. To summarize, “General methods augmented by massive computation are the most effective. Attempts to ‘put’ human knowledge into systems make the systems plateau and ultimately fail.”</summary></entry><entry><title type="html">Humans vs. AI, Summarized</title><link href="http://localhost:4000/Human-AI-Competition/" rel="alternate" type="text/html" title="Humans vs. AI, Summarized" /><published>2019-04-13T00:00:00-04:00</published><updated>2019-04-13T00:00:00-04:00</updated><id>http://localhost:4000/Human-AI-Competition</id><content type="html" xml:base="http://localhost:4000/Human-AI-Competition/">&lt;p&gt;One way researchers have measured AI’s progress has been pitting AI against humans in games. Here I’ll be listing the important occurrences along that timeline.&lt;/p&gt;

&lt;p&gt;1997 - IBM’s Deep Blue defeats Gary Kasparov, the reigning chess world champion at the time.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/2019-04-13-Human-AI-Competition/Kasparov-DeepBlue.jpg&quot; alt=&quot;Kasparov and Deep Blue&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Deep Blue worked via the &lt;a href=&quot;https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning&quot;&gt;alpha-beta search algorithm&lt;/a&gt;, an example of brute force and GOFAI (Good Old-Fashioned AI).
Depending on who you ask, this may not be AI at all, although this may be due to the phenomenon that widely used methods become labeled “Not AI” after a few years of use.&lt;/p&gt;

&lt;p&gt;2011 - IBM’s Watson defeats the reigning Jeopardy! champions Rutter and Jennings.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/2019-04-13-Human-AI-Competition/Jeopardy-Watson.jpg&quot; alt=&quot;Watson&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Watson is much more complicated, utilizing “encyclopedias, dictionaries, thesauri, newswire articles, literary works, and so on”  to supply its NLP (Natural Language Processing) language analysis algorithms, which run in parallel &lt;sup&gt;[&lt;a href=&quot;http://www.aaai.org/Magazine/Watson/watson.php&quot;&gt;1&lt;/a&gt;]&lt;/sup&gt;. Watson’s capacity to run these algorithms in parallel (more than 100 at a time!) is its main achievement &lt;sup&gt;[&lt;a href=&quot;https://www.nytimes.com/2010/06/20/magazine/20Computer-t.html&quot;&gt;2&lt;/a&gt;]&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;An overview of how some of these algorithms work:
“The great shift in artificial intelligence began in the last 10 years, when computer scientists began using statistics to analyze huge piles of documents, like books and news stories. They wrote algorithms that could take any subject and automatically learn what types of words are, statistically speaking, most (and least) associated with it. Using this method, you could put hundreds of articles and books and movie reviews discussing Sherlock Holmes into the computer, and it would calculate that the words “deerstalker hat” and “Professor Moriarty” and “opium” are frequently correlated with one another, but not with, say, the Super Bowl. So at that point you could present the computer with a question that didn’t mention Sherlock Holmes by name, but if the machine detected certain associated words, it could conclude that Holmes was the probable subject — and it could also identify hundreds of other concepts and words that weren’t present but that were likely to be related to Holmes, like “Baker Street” and “chemistry.” &lt;sup&gt;[&lt;a href=&quot;https://www.nytimes.com/2010/06/20/magazine/20Computer-t.html&quot;&gt;2&lt;/a&gt;]&lt;/sup&gt;”&lt;/p&gt;

&lt;p&gt;2015 - DeepMind’s AlphaGo defeats Fan Hui, a Go professional, 5-0.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/2019-04-13-Human-AI-Competition/Hui-Alphago.png&quot; alt=&quot;Fan Hui and Alphago&quot; /&gt;&lt;/p&gt;

&lt;p&gt;From what I understand, AlphaGo receives an input feature (the following picture) and uses a Deep Learning classifier to estimate the probability of the next move over all possible moves, selecting the most probable.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/2019-04-13-Human-AI-Competition/Alphago-features.png&quot; alt=&quot;AlphaGo Features&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Next it utilizes Reinforcement Learning, letting the network play itself. A policy network, which determines which moves lead to the highest probability of winning and a value network, which measures the strategic value of a board layout.&lt;/p&gt;

&lt;p&gt;2016 - AlphaGo defeats Lee Sedol, the world Go champion, 4-1.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/2019-04-13-Human-AI-Competition/Sedol-Alphago.jpg&quot; alt=&quot;Lee Sedol and Alphago&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Today - OpenAI Five, a 5v5 team of bots, defeats OG, Dota 2 world champions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/2019-04-13-Human-AI-Competition/OpenAI-Five.jpg&quot; alt=&quot;OpenAI Five&quot; /&gt;&lt;/p&gt;

&lt;p&gt;OpenAI Five are five neural nets which take as input 20,000 numbers. These numbers are an encoding of the visible game state in Dota, or all the information a human player would have. Actions are chosen by the output of the net, a list of eight numbers. The Five also utilizes self-play to generate gameplay data like AlphaGo, using rewards to inform the &lt;a href=&quot;https://openai.com/blog/openai-baselines-ppo/&quot;&gt;Proximal Policy Optimization&lt;/a&gt; algorithm.&lt;/p&gt;</content><author><name>Ben Gardner</name></author><summary type="html">One way researchers have measured AI’s progress has been pitting AI against humans in games. Here I’ll be listing the important occurrences along that timeline.</summary></entry><entry><title type="html">History of AI</title><link href="http://localhost:4000/History/" rel="alternate" type="text/html" title="History of AI" /><published>2019-03-22T00:00:00-04:00</published><updated>2019-03-22T00:00:00-04:00</updated><id>http://localhost:4000/History</id><content type="html" xml:base="http://localhost:4000/History/">&lt;p&gt;Artificial Intelligence (AI) had its seminal event in the 1956 at the Dartmouth Summer Research Project on AI.
John McCarthy, Marvin Minsky, and others came together to brainstorm on how to create machines and programs that would emulate intelligence.
Symbolic AI was born at this workshop, as well as early Rule-Based Expert Systems.&lt;/p&gt;

&lt;p&gt;There was intense optimism following this workshop. Programs such as the &lt;a href=&quot;https://en.wikipedia.org/wiki/General_Problem_Solver&quot;&gt;General Problem Solver&lt;/a&gt; captured the imagination and had prominent researchers making claims such as “In from three to eight years we will have a machine with the general intelligence of an average human being. &lt;sup&gt;[&lt;a href=&quot;https://books.google.com/books?id=2FMEAAAAMBAJ&amp;amp;pg=PA58&amp;amp;dq=In+from+three+to+eight+years+we+will+have+a+machine+with+the+general+intelligence+of+an+average+human+being#v=onepage&amp;amp;q=In%20from%20three%20to%20eight%20years%20we%20will%20have%20a%20machine%20with%20the%20general%20intelligence%20of%20an%20average%20human%20being&amp;amp;f=false&quot;&gt;1&lt;/a&gt;]&lt;/sup&gt;”&lt;/p&gt;

&lt;p&gt;In the 1970s, after problems in AI proved to be much more difficult than anticipated, the Science Research Council asked the mathematician James Lighthill to write a report on the state of the research in AI. The ‘Lighthill Report’, as it came to be known, was highly critical of AI, and led to the US and British governments defunding the projects they had supported, leading to an ‘AI Winter.’&lt;/p&gt;

&lt;p&gt;Marvin Minsky and Seymour Papert’s book &lt;em&gt;Perceptrons&lt;/em&gt; also came out in this time period, showing that a seemingly promising area of research, Frank Rosenblatt’s early form of a neural network, had more limitations than was previously thought. This led to ten-year gap in ‘connectionism’ (artificial neural network) research.&lt;/p&gt;

&lt;p&gt;The AI Winter began to end in the 1980s with the rise of expert systems. AI was finally commercially viable, and was used by the Digital Equipment Corporation to save $40m per year. Connectionism also began to rebound with Geoffrey Hinton’s popularizing the backpropagation method for neural networks.&lt;/p&gt;

&lt;p&gt;The second AI Winter came about as expert systems began to show their weak points. They were hard to update and maintain, and were vastly overhyped. Again, AI underdelivered relative to its promises, and a withdrawal of funds followed.&lt;/p&gt;

&lt;p&gt;In the current paradigm, artificial neural networks (ANNs), generative adversarial networks (GANs), and reinforcement learning (RL) have all benefitted from ‘big data.’ Rich Sutton recently put out ‘&lt;a href=&quot;http://www.incompleteideas.net/IncIdeas/BitterLesson.html&quot;&gt;The Bitter Lesson&lt;/a&gt;’, explaining that “general methods that leverage computation are ultimately the most effective, and by a large margin.” The hardware-side advances in compute and data availability within the past ten years have ended the second AI Winter and brought about another round of hype surrounding the methods at the beginning of this paragraph, much like expert systems in the 1980s.&lt;/p&gt;</content><author><name>Ben Gardner</name></author><summary type="html">Artificial Intelligence (AI) had its seminal event in the 1956 at the Dartmouth Summer Research Project on AI. John McCarthy, Marvin Minsky, and others came together to brainstorm on how to create machines and programs that would emulate intelligence. Symbolic AI was born at this workshop, as well as early Rule-Based Expert Systems.</summary></entry><entry><title type="html">Hello, World!</title><link href="http://localhost:4000/Hello-World/" rel="alternate" type="text/html" title="Hello, World!" /><published>2019-03-19T00:00:00-04:00</published><updated>2019-03-19T00:00:00-04:00</updated><id>http://localhost:4000/Hello-World</id><content type="html" xml:base="http://localhost:4000/Hello-World/">&lt;p&gt;My first blog post! I’ve been ‘blogging’ for personal record-keeping for a while now, but this will be my first public-facing blog.&lt;/p&gt;

&lt;p&gt;The push to start comes from this tweet:&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Note: all of the &lt;a href=&quot;https://twitter.com/OpenAI?ref_src=twsrc%5Etfw&quot;&gt;@OpenAI&lt;/a&gt; scholars have a research blog&lt;br /&gt;&lt;br /&gt;I don&amp;#39;t think this is an accident - blogging:&lt;br /&gt;&lt;br /&gt;1) forces you to teach AI concepts (forces you to learn)&lt;br /&gt;2) raises awareness of your abilities&lt;br /&gt;3) shows you&amp;#39;re proactive &lt;br /&gt;&lt;br /&gt;Start one!&lt;a href=&quot;https://twitter.com/hashtag/100DaysOfMLCode?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#100DaysOfMLCode&lt;/a&gt;&lt;a href=&quot;https://t.co/wUFmtDjQdO&quot;&gt;https://t.co/wUFmtDjQdO&lt;/a&gt;&lt;/p&gt;&amp;mdash; Andrew Trask (@iamtrask) &lt;a href=&quot;https://twitter.com/iamtrask/status/1106207351026184192?ref_src=twsrc%5Etfw&quot;&gt;March 14, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;My goal is to work for OpenAI/DeepMind/Google Brain after I finish school, and I’m going to use this blog to hone my skills.&lt;/p&gt;

&lt;p&gt;Let’s see where this takes me!&lt;/p&gt;</content><author><name>Ben Gardner</name></author><summary type="html">My first blog post! I’ve been ‘blogging’ for personal record-keeping for a while now, but this will be my first public-facing blog.</summary></entry></feed>